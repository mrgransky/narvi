{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get resized image from a provided path\n",
    "def get_image(path,img_size= (1280,384)):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, img_size, cv2.INTER_LINEAR)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to laod images from a given directory and forming batches\n",
    "def load_images(img_dir, img_size):\n",
    "    print (\"images \", img_dir)\n",
    "    images= []\n",
    "    images_set =[]\n",
    "    for img in glob.glob(img_dir+'/*'):\n",
    "        images.append(get_image(img,img_size))\n",
    "    for i in range(len(images)-1):\n",
    "        img1 = images[i]\n",
    "        img2 = images[i+1]\n",
    "        img = np.concatenate([img1, img2],axis = -1)\n",
    "        images_set.append(img)\n",
    "    print(\"images count : \",len(images_set))\n",
    "    images_set = np.reshape(images_set, (-1, 6, 384, 1280))\n",
    "    return images_set    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper functions for pose preprocessing \n",
    "def isRotationMatrix(R):\n",
    "    \"\"\" Checks if a matrix is a valid rotation matrix\n",
    "        referred from https://www.learnopencv.com/rotation-matrix-to-euler-angles/\n",
    "    \"\"\"\n",
    "    Rt = np.transpose(R)\n",
    "    shouldBeIdentity = np.dot(Rt, R)\n",
    "    I = np.identity(3, dtype = R.dtype)\n",
    "    n = np.linalg.norm(I - shouldBeIdentity)\n",
    "    return n < 1e-6\n",
    "\n",
    "def rotationMatrixToEulerAngles(R):\n",
    "    \"\"\" calculates rotation matrix to euler angles\n",
    "        referred from https://www.learnopencv.com/rotation-matrix-to-euler-angles\n",
    "    \"\"\"\n",
    "    assert(isRotationMatrix(R))\n",
    "    sy = math.sqrt(R[0,0] * R[0,0] +  R[1,0] * R[1,0])\n",
    "    singular = sy < 1e-6\n",
    "\n",
    "    if  not singular :\n",
    "        x = math.atan2(R[2,1] , R[2,2])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = math.atan2(R[1,0], R[0,0])\n",
    "    else :\n",
    "        x = math.atan2(-R[1,2], R[1,1])\n",
    "        y = math.atan2(-R[2,0], sy)\n",
    "        z = 0\n",
    "\n",
    "    return np.array([x, y, z])\n",
    "\n",
    "def getMatrices(all_poses):\n",
    "    all_matrices = []\n",
    "    for i in range(len(all_poses)):\n",
    "        #print(\"I: \",i)\n",
    "        j = all_poses[i]\n",
    "        #print(\"J:   \",j)\n",
    "        p = np.array([j[3], j[7], j[11]])\n",
    "        #print(\"P:   \", p)\n",
    "        R = np.array([[j[0],j[1],j[2]],\n",
    "                [j[4],j[5],j[6]],\n",
    "                [j[8],j[9],j[10]]])\n",
    "        #print(\"R:   \", R)\n",
    "        angles = rotationMatrixToEulerAngles(R)\n",
    "        #print(\"Angles: \",angles)\n",
    "        matrix = np.concatenate((p,angles))\n",
    "        #print(\"MATRIX: \", matrix)\n",
    "        all_matrices.append(matrix)\n",
    "    return all_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to get poses form a given location \n",
    "def load_poses(pose_file):\n",
    "    print (\"pose \",pose_file)\n",
    "    poses = []\n",
    "    poses_set = []\n",
    "    with open(pose_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            pose = np.fromstring(line, dtype=float, sep=' ')\n",
    "            poses.append(pose)\n",
    "    poses = getMatrices(poses)\n",
    "    for i in range(len(poses)-1):\n",
    "        pose1 = poses[i]\n",
    "        pose2 = poses[i+1]\n",
    "        finalpose = pose2-pose1\n",
    "        poses_set.append(finalpose)\n",
    "    print(\"poses count: \",len(poses_set))\n",
    "    return poses_set          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primary dataloader function to get both images and poses\n",
    "def VODataLoader(datapath,img_size= (1280,384), test=False):\n",
    "    print (datapath)\n",
    "    poses_path = os.path.join(datapath,'poses')\n",
    "    img_path = os.path.join(datapath,'sequences')\n",
    "    if test:\n",
    "        sequences = ['03']  #Kindly use this sequence only for testing as this has mininum number of images\n",
    "    else:\n",
    "        #Uncomment below and comment the next to next line to work with larger data \n",
    "        #sequences= ['01','03','06']\n",
    "        sequences = ['01']  \n",
    "        \n",
    "    images_set = []\n",
    "    odometry_set = []\n",
    "    \n",
    "    for sequence in sequences:\n",
    "        images_set.append(torch.FloatTensor(load_images(os.path.join(img_path,sequence,'image_0'),img_size)))\n",
    "        odometry_set.append(torch.FloatTensor(load_poses(os.path.join(poses_path,sequence+'.txt'))))\n",
    "    \n",
    "    return images_set, odometry_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/xenial/Datasets/KITTI\n",
      "('images ', '/home/xenial/Datasets/KITTI/sequences/01/image_0')\n",
      "('images count : ', 1100)\n",
      "('pose ', '/home/xenial/Datasets/KITTI/poses/01.txt')\n",
      "('poses count: ', 1100)\n"
     ]
    }
   ],
   "source": [
    "#dataload\n",
    "X,y = VODataLoader(\"/home/xenial/Datasets/KITTI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of X :\n",
      "torch.Size([1100, 6, 384, 1280])\n",
      "Details of y :\n",
      "torch.Size([1100, 6])\n"
     ]
    }
   ],
   "source": [
    "print(\"Details of X :\")\n",
    "# print(type(X)) \n",
    "# print(type(X[0]))\n",
    "# print(len(X)) \n",
    "# print(len(X[0])) \n",
    "print(X[0].size())\n",
    "print(\"Details of y :\")\n",
    "# print(type(y))\n",
    "# print(type(y[0]))\n",
    "# print(len(y))\n",
    "# print(len(y[0]))\n",
    "print(y[0].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Details of X :\n",
      "torch.Size([110, 10, 6, 384, 1280])\n",
      "Details of y :\n",
      "torch.Size([110, 10, 6])\n"
     ]
    }
   ],
   "source": [
    "#Converting lists containing tensors to tensors as per the batchsize (10)\n",
    "X=torch.stack(X).view(-1,10,6, 384, 1280)\n",
    "y=torch.stack(y).view(-1,10,6)\n",
    "print(\"Details of X :\")\n",
    "print(X.size())\n",
    "print(\"Details of y :\")\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to display image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img):\n",
    "    plt.figure\n",
    "    plt.imshow(img, 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining neural network as per RP by Sen Wang\n",
    "class DeepVONet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepVONet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)) #6 64\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d (64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d (128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.conv3_1 = nn.Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.relu3_1 = nn.ReLU(inplace=True)\n",
    "        self.conv4 = nn.Conv2d (256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        self.conv4_1 = nn.Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.relu4_1 = nn.ReLU(inplace=True)\n",
    "        self.conv5 = nn.Conv2d (512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        self.conv5_1 = nn.Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "        self.relu5_1 = nn.ReLU(inplace=True)\n",
    "        self.conv6 = nn.Conv2d (512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.lstm1 = nn.LSTMCell(20*6*1024, 100)\n",
    "        self.lstm2 = nn.LSTMCell(100, 100)\n",
    "        self.fc = nn.Linear(in_features=100, out_features=6)\n",
    "\n",
    "        self.reset_hidden_states()\n",
    "\n",
    "    def reset_hidden_states(self, size=10, zero=True):\n",
    "        if zero == True:\n",
    "            self.hx1 = Variable(torch.zeros(size, 100))\n",
    "            self.cx1 = Variable(torch.zeros(size, 100))\n",
    "            self.hx2 = Variable(torch.zeros(size, 100))\n",
    "            self.cx2 = Variable(torch.zeros(size, 100))\n",
    "        else:\n",
    "            self.hx1 = Variable(self.hx1.data)\n",
    "            self.cx1 = Variable(self.cx1.data)\n",
    "            self.hx2 = Variable(self.hx2.data)\n",
    "            self.cx2 = Variable(self.cx2.data)\n",
    "\n",
    "        if next(self.parameters()).is_cuda == True:\n",
    "            self.hx1 = self.hx1.cuda()\n",
    "            self.cx1 = self.cx1.cuda()\n",
    "            self.hx2 = self.hx2.cuda()\n",
    "            self.cx2 = self.cx2.cuda()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv3_1(x)\n",
    "        x = self.relu3_1(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.conv4_1(x)\n",
    "        x = self.relu4_1(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.conv5_1(x)\n",
    "        x = self.relu5_1(x)\n",
    "        x = self.conv6(x)\n",
    "        #print(x.size())\n",
    "        x = x.view(x.size(0), 20 * 6 * 1024)\n",
    "        #print(x.size())\n",
    "        self.hx1, self.cx1 = self.lstm1(x, (self.hx1, self.cx1))\n",
    "        x = self.hx1\n",
    "        self.hx2, self.cx2 = self.lstm2(x, (self.hx2, self.cx2))\n",
    "        x = self.hx2\n",
    "        #print(x.size())\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def training_model(model, train_num, X, y, epoch_num=25):\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        print(\"Epoch : \", epoch+1)\n",
    "        for i in range(train_num):\n",
    "            print(\"Train num :\", i+1)\n",
    "            inputs = X[i]\n",
    "            #print(len(inputs))\n",
    "            labels = y[i]\n",
    "            #print(len(labels))\n",
    "            model.zero_grad()\n",
    "            model.reset_hidden_states()\n",
    "            #optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            if(epoch == (epoch_num-1) and (i > train_num-5)):\n",
    "                print(\"Outputs \", outputs)\n",
    "                print(\"Labels \", labels)\n",
    "            #print(outputs)\n",
    "            #print(labels)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        print('Epoch : %d Loss: %.3f' %(epoch+1, running_loss/train_num))\n",
    "\n",
    "\n",
    "    print('Finished Training')\n",
    "    print (\"Time taken in Training {0}\".format((time.time() - start_time)))\n",
    "\n",
    "#Testing functions, it is predicting the output for test sequence as per the model\n",
    "def testing_model (model, test_num, X):\n",
    "    start_time = time.time()\n",
    "    Y_output = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(test_num):\n",
    "            inputs = X[i]\n",
    "            outputs = model(inputs)\n",
    "            Y_output.append(outputs)\n",
    "    print (\"Time taken in Testing {0}\".format((time.time() - start_time)))\n",
    "    return torch.stack(Y_output)\n",
    "\n",
    "#Helper functions to get accuracy\n",
    "def get_accuracy(outputs, labels, batch_size):\n",
    "    diff =0\n",
    "    for i in range(batch_size):\n",
    "        for j in range(10):\n",
    "            out = outputs[j].detach().numpy()\n",
    "            lab = labels[j].detach().numpy()\n",
    "            print \"out =\\n{}\\nlab =\\n{}\".format(out, lab)\n",
    "            diff+=get_mse_diff(out,lab)\n",
    "    #print(\"Loss : \",diff/(batch_size*10),\"%\")\n",
    "    print(\"Accuracy : \",(1 -diff/(batch_size*10))*100,\"%\")\n",
    "    \n",
    "def get_mse_diff(x,y):\n",
    "    diff= 0\n",
    "    for i in range(6):\n",
    "        diff += (x[i]-y[i])*(x[i]-y[i])\n",
    "    return diff/6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepVONet(\n",
      "  (conv1): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "  (relu1): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (relu2): ReLU(inplace=True)\n",
      "  (conv3): Conv2d(128, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (relu3): ReLU(inplace=True)\n",
      "  (conv3_1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu3_1): ReLU(inplace=True)\n",
      "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (relu4): ReLU(inplace=True)\n",
      "  (conv4_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu4_1): ReLU(inplace=True)\n",
      "  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (relu5): ReLU(inplace=True)\n",
      "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu5_1): ReLU(inplace=True)\n",
      "  (conv6): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (lstm1): LSTMCell(122880, 100)\n",
      "  (lstm2): LSTMCell(100, 100)\n",
      "  (fc): Linear(in_features=100, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Creating model and defining loss and optimizer to be used \n",
    "model = DeepVONet()\n",
    "print(model)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = torch.nn.MSELoss()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment lines below to see model paramters \n",
    "# for parameter in model.parameters():\n",
    "#     print(len(parameter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch : ', 1)\n",
      "('Train num :', 1)\n",
      "('Train num :', 2)\n",
      "('Train num :', 3)\n",
      "('Train num :', 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_model(model,10,X,y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the model\n",
    "#torch.save(model.state_dict(), 'DeepVO.pt')\n",
    "#Load model\n",
    "# model_loaded = torch.load('DeepVO.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test,y_test = VODataLoader(\"/home/xenial/Datasets/KITTI\", test=True)\n",
    "X_test=torch.stack(X_test).view(-1,10,6, 384, 1280)\n",
    "y_test=torch.stack(y_test).view(-1,10,6)\n",
    "print(X_test.size())\n",
    "print(y_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting predictions from the model \n",
    "test_batch_size = 10 #Based on this count only batches will be process, not as per the total number of batches provided\n",
    "y_output = testing_model(model,test_batch_size,X)\n",
    "print(y_output.size())\n",
    "#Saving outputs\n",
    "torch.save(y_output,\"y_output.pt\")\n",
    "#getting accuracy\n",
    "get_accuracy(y_output,y_test,test_batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
